{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1135f7450>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123) # specify random seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], requires_grad=True)\n",
      "shape --> torch.Size([2, 3])\n",
      "dtype --> torch.float32\n",
      "differentiable?--> True\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # specify device\n",
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]], device=device, requires_grad=True, dtype=torch.float)\n",
    "print(my_tensor)\n",
    "print('shape -->',my_tensor.shape)\n",
    "print('dtype -->',my_tensor.dtype)\n",
    "print('differentiable?-->',my_tensor.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0524e+21, 2.1062e+23, 3.2504e+21],\n",
      "        [5.4077e+22, 2.6077e-09, 8.5078e-07],\n",
      "        [2.5667e-09, 2.6250e-09, 1.0733e-08]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.2961, 0.5166, 0.2517],\n",
      "        [0.6886, 0.0740, 0.8665],\n",
      "        [0.1366, 0.1025, 0.1841]])\n",
      "torch.Size([3, 3])\n",
      "tensor([1, 3, 5, 7, 9])\n",
      "tensor([[1, 2],\n",
      "        [2, 1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(size=(3,3))\n",
    "print(x)\n",
    "x = torch.zeros(size=(3,3))\n",
    "print(x)\n",
    "x = torch.rand((3,3))\n",
    "print(x)\n",
    "x = torch.eye(3)\n",
    "print(x.shape)\n",
    "x = torch.arange(1,10,2)\n",
    "print(x)\n",
    "x = torch.randint(1,3,(2,2))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tensors to different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True])\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(4)\n",
    "print(t.bool()) # to bool\n",
    "print(t.float()) #float32\n",
    "print(t.double()) # float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array to tensor and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64)\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_array = np.zeros((3,3))\n",
    "tensor= torch.from_numpy(np_array) # to tensor\n",
    "numpy = tensor.numpy() #to numpy\n",
    "print(tensor)\n",
    "print(numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  7, 10])\n",
      "tensor([0.2500, 0.4000, 0.4286])\n",
      "tensor([ 5.,  7., 10.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([4,5,7])\n",
    "z = torch.empty(3)\n",
    "torch.add(x,y,out=z)\n",
    "print(x+y)\n",
    "print(x/y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inplace\n",
    "underscore after operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "x.add_(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "## exponent\n",
    "x = torch.tensor([1,2,3])\n",
    "y=x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "#comparasion\n",
    "x = torch.tensor([1,2,3])\n",
    "z = x>2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3717, 0.3452],\n",
      "        [0.4107, 0.2547]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "x = torch.rand((2,2))\n",
    "y = torch.rand((2,2))\n",
    "z = torch.mm(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "x = torch.ones((2,2))\n",
    "z = x**2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[1, 1],\n",
      "        [2, 1]])\n",
      "y tensor([[8, 4],\n",
      "        [2, 6]])\n",
      "x*y tensor([[8, 4],\n",
      "        [4, 6]])\n",
      "MM tensor([[10, 10],\n",
      "        [18, 14]])\n",
      "dot tensor(12)\n"
     ]
    }
   ],
   "source": [
    "# elementwise multiplication (Hadaman product)\n",
    "x = torch.randint(1,10,(2,2))\n",
    "y = torch.randint(1,10,(2,2))\n",
    "print('x', x)\n",
    "print('y', y)\n",
    "print('x*y', x*y)\n",
    "print('MM', torch.mm(x,y))\n",
    "#x[:,0]\n",
    "print('dot', torch.dot(x[:,0],y[:,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9933, 0.4830, 0.7707, 0.7305, 1.1820, 0.9965],\n",
      "         [2.1352, 1.0474, 1.2415, 1.0830, 1.8570, 1.2905],\n",
      "         [2.5442, 1.2166, 1.6466, 1.5063, 2.4719, 1.8105],\n",
      "         [1.2928, 0.8484, 0.7431, 0.8570, 1.1538, 0.9195],\n",
      "         [2.4484, 1.0700, 1.6383, 1.4939, 1.9658, 1.6023],\n",
      "         [1.0497, 0.3138, 0.7818, 0.5896, 1.1073, 0.7808],\n",
      "         [1.9676, 0.6707, 1.6358, 1.4153, 2.2471, 1.8249],\n",
      "         [1.4078, 0.4564, 1.2238, 1.1506, 1.7396, 1.3090],\n",
      "         [1.7316, 0.6368, 1.2803, 1.0737, 2.0214, 1.3978],\n",
      "         [1.2671, 0.7145, 0.7536, 0.7071, 1.0613, 0.8993]],\n",
      "\n",
      "        [[1.7797, 1.8384, 2.2031, 1.1907, 0.6372, 1.8469],\n",
      "         [1.5220, 1.6340, 2.2625, 1.1988, 0.6432, 1.8475],\n",
      "         [1.8601, 1.2881, 1.8931, 1.4941, 0.4552, 1.4391],\n",
      "         [1.0040, 1.1169, 1.4871, 0.9475, 0.3064, 0.8988],\n",
      "         [1.9357, 1.4987, 2.1200, 1.6230, 0.4611, 1.4532],\n",
      "         [1.4224, 1.0971, 1.5018, 1.1886, 0.2993, 0.9650],\n",
      "         [1.5960, 1.5484, 1.9864, 1.3976, 0.5238, 1.4806],\n",
      "         [1.7884, 1.8866, 2.2818, 1.5608, 0.4632, 1.3660],\n",
      "         [1.6761, 1.6007, 2.0052, 1.3905, 0.5150, 1.4830],\n",
      "         [0.8401, 1.1486, 1.4389, 0.7677, 0.3170, 0.8953]]])\n"
     ]
    }
   ],
   "source": [
    "## Batch matrix multiplication\n",
    "batch = 2\n",
    "p = 10\n",
    "q = 5\n",
    "r = 6\n",
    "tensor1 = torch.rand((batch,p,q))\n",
    "tensor2 = torch.rand((batch,q,r))\n",
    "tensor3 = torch.bmm(tensor1,tensor2)\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.1735, 0.9247, 0.6166],\n",
      "        [0.3608, 0.5325, 0.6559],\n",
      "        [0.3232, 0.1126, 0.5034]])\n",
      "y tensor([[0.5091, 0.5101, 0.4270]])\n",
      "x-y tensor([[-0.3356,  0.4147,  0.1895],\n",
      "        [-0.1483,  0.0224,  0.2288],\n",
      "        [-0.1859, -0.3975,  0.0763]])\n",
      "x**y tensor([[0.4100, 0.9609, 0.8134],\n",
      "        [0.5951, 0.7251, 0.8352],\n",
      "        [0.5627, 0.3282, 0.7459]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((3,3))\n",
    "y = torch.rand((1,3))\n",
    "\n",
    "print('x', x)\n",
    "print('y', y)\n",
    "print('x-y', x-y)\n",
    "print('x**y', x**y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x --> tensor([[2, 1],\n",
      "        [1, 1]])\n",
      "x_shape -->  torch.Size([2, 2])\n",
      " sum_x --> tensor([3, 2])\n",
      " sum_y --> tensor([3, 2])\n",
      "value tensor([2, 1])\n",
      "indx tensor([0, 0])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randint(1,3,(2,2))\n",
    "\n",
    "sum_x = torch.sum(x,dim=0)\n",
    "sum_y= torch.sum(x,dim=1)\n",
    "\n",
    "print(f'x --> {x}')\n",
    "\n",
    "print('x_shape --> ',x.shape)\n",
    "\n",
    "print(f' sum_x --> {sum_x}')\n",
    "\n",
    "print(f' sum_y --> {sum_y}')\n",
    "\n",
    "value,indice = torch.max(x, dim=1)\n",
    "\n",
    "print('value', value)\n",
    "print('indx', indice)\n",
    "print(torch.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4871)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,4))\n",
    "print(torch.mean(x.float()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2288, 0.5185, 0.5489, 0.0977]])\n",
      "tensor([[0.4000, 0.5185, 0.5489, 0.4000]])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,4))\n",
    "print(x)\n",
    "print(torch.clamp(x,min=0.4, max=0.8))\n",
    "print(torch.any(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## einsum\n",
    "Can be used to make any time of matrix operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.array([[1,2],[3,4]]))\n",
    "y = torch.from_numpy(np.array([[5,6],[7,8]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x --> tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "y --> tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "print('x -->', x)\n",
    "print('y -->', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colapse rows--> tensor([4, 6])\n",
      "colapse cols--> tensor([3, 7])\n"
     ]
    }
   ],
   "source": [
    "print('colapse rows-->',torch.einsum('ab->b',x))\n",
    "print('colapse cols-->',torch.einsum('ab->a',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hadamard product\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "\n",
      "Sum of Hadamard product\n",
      "tensor(70)\n",
      "\n",
      "Matrix multiplication\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "\n",
      "Matrix multiplication\n",
      "tensor(134)\n"
     ]
    }
   ],
   "source": [
    "print('\\nHadamard product')\n",
    "print(torch.einsum('ab,ab->ab',x,y))\n",
    "\n",
    "print('\\nSum of Hadamard product (dot product)')\n",
    "print(torch.einsum('ab,ab->',x,y))\n",
    "\n",
    "print('\\nMatrix multiplication')\n",
    "print(torch.einsum('ab,bc->ac',x,y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1364, 0.6918, 0.3545, 0.7969],\n",
      "        [0.0061, 0.2528, 0.0882, 0.6997]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "r = torch.rand((2,4))\n",
    "print(r)\n",
    "print(torch.einsum('ij->ji',r).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([[1,2,3],[5,6,7]]))\n",
    "print(x.shape)\n",
    "y = x.view(3,-1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5125], requires_grad=True)\n",
      "y  tensor([2.2626], grad_fn=<AddBackward0>)\n",
      "tensor([1.0249], grad_fn=<MulBackward0>)\n",
      "tensor([5.0249], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1), requires_grad=True)\n",
    "print(x)\n",
    "y= x**2 + 2\n",
    "print('y ', y)\n",
    "z = 2*x \n",
    "print(z)\n",
    "s = 2*x + 4\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  tensor([0.1549, 0.6881, 0.4900, 0.0164], requires_grad=True)\n",
      "y  tensor([0.7690, 0.7674, 0.4058, 0.1548], requires_grad=True)\n",
      "z  tensor([0.5201, 0.8773, 0.9577, 0.1226], requires_grad=True)\n",
      "new x  tensor([0.1549, 0.6881, 0.4900, 0.0164])\n",
      "tensor([0.7690, 0.7674, 0.4058, 0.1548])\n",
      "tensor([2.5201, 2.8773, 2.9577, 2.1226])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,requires_grad=True)\n",
    "y = torch.rand(4,requires_grad=True)\n",
    "z = torch.rand(4,requires_grad=True)\n",
    "print('x ', x)\n",
    "print('y ', y)\n",
    "print('z ', z)\n",
    "\n",
    "# first method\n",
    "x.requires_grad=False\n",
    "print('new x ', x)\n",
    "\n",
    "#second method\n",
    "print(y.detach())\n",
    "\n",
    "#third method\n",
    "with torch.no_grad():\n",
    "    print(z+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.9785], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor(2)\n",
    "x = torch.rand(1)\n",
    "w = torch.tensor(1, dtype = torch.float, requires_grad=True)\n",
    "y_hat = w*x\n",
    "loss = (y-y_hat)**2\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression in numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 1.2 loss 30.000000\n",
      "epoch 3 w 1.871999988555908 loss 0.768000\n",
      "epoch 5 w 1.9795200133323667 loss 0.019661\n",
      "epoch 7 w 1.9967231869697568 loss 0.000503\n",
      "epoch 9 w 1.999475698471069 loss 0.000013\n",
      "epoch 11 w 1.9999160599708554 loss 0.000000\n",
      "epoch 13 w 1.9999865984916685 loss 0.000000\n",
      "epoch 15 w 1.9999978351593015 loss 0.000000\n",
      "epoch 17 w 1.9999996304512022 loss 0.000000\n",
      "epoch 19 w 1.9999999165534972 loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4], dtype=np.float32)\n",
    "y= np.array([2,4,6,8], dtype=np.float32)\n",
    "w= 0.0\n",
    "\n",
    "def forward(X):\n",
    "    return w * X\n",
    "\n",
    "def loss(Y, Y_pred):\n",
    "    return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "def gradient(X, Y, Y_pred):\n",
    "    return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "n_iter = 20\n",
    "lr = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    pred = forward(x)\n",
    "    l = loss(y,pred)\n",
    "    dw = gradient(x,y,pred)\n",
    "    w -= lr*dw\n",
    "    if epoch %2 ==0:\n",
    "        print(f'epoch {epoch+1} w {w} loss {l:3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 0.29999998211860657 loss 30.000000\n",
      "epoch 101 w 1.9999996423721313 loss 0.000000\n",
      "epoch 201 w 1.9999996423721313 loss 0.000000\n",
      "epoch 301 w 1.9999996423721313 loss 0.000000\n",
      "epoch 401 w 1.9999996423721313 loss 0.000000\n",
      "epoch 501 w 1.9999996423721313 loss 0.000000\n",
      "epoch 601 w 1.9999996423721313 loss 0.000000\n",
      "epoch 701 w 1.9999996423721313 loss 0.000000\n",
      "epoch 801 w 1.9999996423721313 loss 0.000000\n",
      "epoch 901 w 1.9999996423721313 loss 0.000000\n",
      "prediction after training 10.00\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "y= torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "def forward(X):\n",
    "    return w * X\n",
    "\n",
    "def loss(Y, Y_pred):\n",
    "    return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "# def gradient(X, Y, Y_pred):\n",
    "#     return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "n_iter = 1000\n",
    "lr = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    pred = forward(x)\n",
    "    l = loss(y,pred)\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= lr*w.grad\n",
    "    w.grad.zero_()\n",
    "    if epoch %100 ==0:\n",
    "        print(f'epoch {epoch+1} w {w} loss {l:3f}')\n",
    "print(f\"prediction after training {forward(5):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace parts with torch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 0.0009669065475463867 loss 55.290382\n",
      "epoch 1001 w 2.0015087127685547 loss 0.000003\n",
      "epoch 2001 w 2.0000765323638916 loss 0.000000\n",
      "last epoch 2040 w 2.0000674724578857 loss 0.000000\n",
      "prediction after training 10.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "n_iter = 10000\n",
    "lr = 0.01\n",
    "\n",
    "#x= torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "#y= torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "x= torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "y= torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "x_test= torch.tensor([[5]], dtype=torch.float32)\n",
    "n_samples, n_features  = x.shape\n",
    "n_inputs, n_outputs = n_features,n_features\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "model = nn.Linear(n_inputs, n_outputs)\n",
    "#def forward(X):\n",
    "#   return w * X\n",
    "\n",
    "## replace loss with MSEloss\n",
    "loss= nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) # will be used to do update\n",
    "#def loss(Y, Y_pred):\n",
    " #   return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "# def gradient(X, Y, Y_pred):\n",
    "#     return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "w_prev = 99999999\n",
    "for epoch in range(n_iter):\n",
    "    pred = model(x)\n",
    "    l = loss(y,pred)\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    " #   with torch.no_grad():\n",
    " #       w -= lr*w.grad\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #w.grad.zero_()\n",
    "    w,b = model.parameters()\n",
    "    w_now = w[0][0].item()\n",
    "    if w_now == w_prev:\n",
    "        print(f'last epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "        break\n",
    "    w_prev = w_now\n",
    "    if epoch %1000 ==0:\n",
    "        w,b = model.parameters()\n",
    "        print(f'epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "print(f\"prediction after training {model(x_test).item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 1.0181353092193604 loss 10.668782\n",
      "epoch 1001 w 1.9954642057418823 loss 0.000030\n",
      "epoch 2001 w 1.9997735023498535 loss 0.000000\n",
      "last epoch 2635 w 1.9999659061431885 loss 0.000000\n",
      "prediction after training 10.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "n_iter = 10000\n",
    "lr = 0.01\n",
    "\n",
    "#x= torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "#y= torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "x= torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "y= torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "x_test= torch.tensor([[5]], dtype=torch.float32)\n",
    "n_samples, n_features  = x.shape\n",
    "n_inputs, n_outputs = n_features,n_features\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        self.lin = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(n_inputs, n_outputs)\n",
    "#def forward(X):\n",
    "#   return w * X\n",
    "\n",
    "## replace loss with MSEloss\n",
    "loss= nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) # will be used to do update\n",
    "#def loss(Y, Y_pred):\n",
    " #   return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "# def gradient(X, Y, Y_pred):\n",
    "#     return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "w_prev = 99999999\n",
    "for epoch in range(n_iter):\n",
    "    pred = model(x)\n",
    "    l = loss(y,pred)\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    " #   with torch.no_grad():\n",
    " #       w -= lr*w.grad\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #w.grad.zero_()\n",
    "    w,b = model.parameters()\n",
    "    w_now = w[0][0].item()\n",
    "    if w_now == w_prev:\n",
    "        print(f'last epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "        break\n",
    "    w_prev = w_now\n",
    "    if epoch %1000 ==0:\n",
    "        w,b = model.parameters()\n",
    "        print(f'epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "print(f\"prediction after training {model(x_test).item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "Datasets and Dataloaders are two basic building blocks used for handling data.\n",
    "\n",
    "From the pytorch website, Datasets store samples (features) and their corresponding target values \n",
    "\n",
    "DataLoader makes the Dataset an iterable. Using these two is a way to prevent data leakage in an algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a a custom Dataset\n",
    "The class for a custom Dataset should subclass the Dataset class. \n",
    "\n",
    "It should have three dunder methods: init, len and getitem.\n",
    "\n",
    "- The init method will initialize and specify any necessary transform to be made on the data.\n",
    "\n",
    "- The len method will return the number of samples.\n",
    "\n",
    "- The getitem method will read the data, apply a specified transform if any and return a sample from the data at a given index.\n",
    "\n",
    "\n",
    "As example, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "In torch, the template for creating a machine learning algorithm is as follows:\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## prepare the data\n",
    "X_data, y_data = datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7f94b8b1e41b02170d45ac71ce2d6b011e7cd56207b4c480f5292088bcfab93"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}