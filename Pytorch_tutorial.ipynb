{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], requires_grad=True)\n",
      "torch.Size([2, 3])\n",
      "torch.float32\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "my_tensor = torch.tensor([[1,2,3],[4,5,6]], device=device, requires_grad=True, dtype=torch.float)\n",
    "print(my_tensor)\n",
    "print(my_tensor.shape)\n",
    "print(my_tensor.dtype)\n",
    "print(my_tensor.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 9.8091e-45, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.3861, 0.7243, 0.6378],\n",
      "        [0.6355, 0.5319, 0.5843],\n",
      "        [0.1040, 0.9269, 0.5314]])\n",
      "torch.Size([3, 3])\n",
      "tensor([1, 3, 5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(size=(3,3))\n",
    "print(x)\n",
    "x = torch.zeros(size=(3,3))\n",
    "print(x)\n",
    "x = torch.rand((3,3))\n",
    "print(x)\n",
    "x = torch.eye(3)\n",
    "print(x.shape)\n",
    "x = torch.arange(1,10,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert tensors to different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True,  True,  True])\n",
      "tensor([0., 1., 2., 3.])\n",
      "tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "t = torch.arange(4)\n",
    "print(t.bool()) # to bool\n",
    "print(t.float()) #float32\n",
    "print(t.double()) # float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array to tensor and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float64)\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_array = np.zeros((3,3))\n",
    "tensor= torch.from_numpy(np_array) # to tensor\n",
    "numpy = tensor.numpy() #to numpy\n",
    "print(tensor)\n",
    "print(numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  7, 10])\n",
      "tensor([0.2500, 0.4000, 0.4286])\n",
      "tensor([ 5.,  7., 10.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "y = torch.tensor([4,5,7])\n",
    "z = torch.empty(3)\n",
    "torch.add(x,y,out=z)\n",
    "print(x+y)\n",
    "print(x/y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inplace\n",
    "underscore after operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "x.add_(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "## exponent\n",
    "x = torch.tensor([1,2,3])\n",
    "y=x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "#comparasion\n",
    "x = torch.tensor([1,2,3])\n",
    "z = x>2\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2037, 0.4075],\n",
      "        [0.9940, 0.1616]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "x = torch.rand((2,2))\n",
    "y = torch.rand((2,2))\n",
    "z = torch.mm(x,y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "x = torch.ones((2,2))\n",
    "z = x**2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.4043, 0.2669],\n",
      "        [0.4329, 0.3080]])\n",
      "y tensor([[0.8569, 0.6128],\n",
      "        [0.8669, 0.6849]])\n",
      "x*y tensor([[0.3464, 0.1635],\n",
      "        [0.3753, 0.2109]])\n",
      "MM tensor([[0.5778, 0.4305],\n",
      "        [0.6380, 0.4762]])\n",
      "dot tensor(0.7217)\n"
     ]
    }
   ],
   "source": [
    "# elementwise multiplication (Hadaman product)\n",
    "x = torch.rand((2,2))\n",
    "y = torch.rand((2,2))\n",
    "print('x', x)\n",
    "print('y', y)\n",
    "print('x*y', x*y)\n",
    "print('MM', torch.mm(x,y))\n",
    "print('dot', torch.dot(x[:,0],y[:,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41871276"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8244*0.5079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.3669, 1.4317, 1.4266, 1.9602, 0.9246, 2.3821],\n",
      "         [0.9943, 1.2601, 1.0503, 1.6554, 0.8719, 1.6180],\n",
      "         [0.6277, 1.1764, 0.5245, 0.9831, 1.0619, 1.2530],\n",
      "         [0.8913, 1.0824, 0.8982, 1.3575, 0.8366, 1.7261],\n",
      "         [0.9804, 0.9426, 1.1262, 1.6299, 0.4847, 1.4991],\n",
      "         [1.1019, 1.1951, 1.1214, 1.6683, 0.9324, 2.1028],\n",
      "         [0.6191, 0.5937, 0.6887, 1.0554, 0.3689, 0.8930],\n",
      "         [1.2190, 1.6845, 1.1463, 1.8267, 1.4064, 2.3176],\n",
      "         [0.7256, 0.8091, 0.7527, 0.9627, 0.4572, 1.2068],\n",
      "         [0.6350, 0.9116, 0.5739, 0.9875, 0.7973, 1.0451]],\n",
      "\n",
      "        [[1.1294, 0.8574, 0.7147, 1.2580, 0.5445, 0.8397],\n",
      "         [2.2424, 1.6424, 1.2594, 2.3753, 1.0609, 1.4496],\n",
      "         [2.8146, 2.2225, 1.6820, 3.1515, 1.5649, 1.9485],\n",
      "         [2.2723, 1.9786, 1.5930, 2.7220, 1.2241, 1.6923],\n",
      "         [1.4958, 1.4091, 0.5970, 1.8307, 0.7948, 1.0305],\n",
      "         [1.2920, 1.1067, 0.5353, 1.4862, 0.7620, 0.8380],\n",
      "         [1.7591, 1.3844, 0.9675, 1.8833, 1.0300, 0.9783],\n",
      "         [0.8967, 0.6072, 0.5857, 0.9293, 0.5235, 0.6100],\n",
      "         [1.8572, 1.5927, 0.7586, 2.1685, 1.0642, 1.2973],\n",
      "         [1.4284, 1.0505, 0.7245, 1.5513, 0.5423, 1.0409]]])\n"
     ]
    }
   ],
   "source": [
    "## Batch matrix multiplication\n",
    "batch = 2\n",
    "p = 10\n",
    "q = 5\n",
    "r = 6\n",
    "tensor1 = torch.rand((batch,p,q))\n",
    "tensor2 = torch.rand((batch,q,r))\n",
    "tensor3 = torch.bmm(tensor1,tensor2)\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[0.7223, 0.1175, 0.0398],\n",
      "        [0.2455, 0.7528, 0.6102],\n",
      "        [0.8631, 0.6835, 0.3924]])\n",
      "y tensor([[0.7552, 0.9181, 0.6746]])\n",
      "x-y tensor([[-0.0329, -0.8005, -0.6348],\n",
      "        [-0.5097, -0.1653, -0.0644],\n",
      "        [ 0.1079, -0.2346, -0.2823]])\n",
      "x**y tensor([[0.7822, 0.1401, 0.1136],\n",
      "        [0.3462, 0.7705, 0.7166],\n",
      "        [0.8948, 0.7051, 0.5320]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((3,3))\n",
    "y = torch.rand((1,3))\n",
    "\n",
    "print('x', x)\n",
    "print('y', y)\n",
    "print('x-y', x-y)\n",
    "print('x**y', x**y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "tensor([0.3310, 0.7887, 0.6801])\n",
      "tensor([1.7998])\n",
      "value tensor([0.7887])\n",
      "indx tensor([1])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,3))\n",
    "sum_x = torch.sum(x,dim=0)\n",
    "sum_y= torch.sum(x,dim=1)\n",
    "print(x.shape)\n",
    "print(sum_x)\n",
    "print(sum_y)\n",
    "\n",
    "value, indice = torch.max(x, dim=1)\n",
    "\n",
    "print('value', value)\n",
    "print('indx', indice)\n",
    "print(torch.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4772)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,4))\n",
    "print(torch.mean(x.float()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5329, 0.6062, 0.0108, 0.6047]])\n",
      "tensor([[0.5329, 0.6062, 0.4000, 0.6047]])\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1,4))\n",
    "print(x)\n",
    "print(torch.clamp(x,min=0.4, max=0.8))\n",
    "print(torch.any(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2734, 0.5167, 0.5722, 0.1782],\n",
      "        [0.9019, 0.2451, 0.7864, 0.9180]])\n",
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "r = torch.rand((2,4))\n",
    "print(r)\n",
    "print(torch.einsum('ij->ji',r).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([[1,2,3],[5,6,7]]))\n",
    "print(x.shape)\n",
    "y = x.view(3,-1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4234], requires_grad=True)\n",
      "y  tensor([2.4234], grad_fn=<AddBackward0>)\n",
      "tensor([0.8468], grad_fn=<MulBackward0>)\n",
      "tensor([4.8468], grad_fn=<AddBackward0>)\n",
      "dy/dx  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eewusiannan/Library/Python/3.8/lib/python/site-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1), requires_grad=True)\n",
    "print(x)\n",
    "y= x + 2\n",
    "print('y ', y)\n",
    "z = 2*x \n",
    "print(z)\n",
    "s = 2*x + 4\n",
    "print(s)\n",
    "y.backward()\n",
    "print('dy/dx ',y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  tensor([0.9829, 0.8345, 0.3054, 0.6207], requires_grad=True)\n",
      "y  tensor([0.3428, 0.1822, 0.3914, 0.0169], requires_grad=True)\n",
      "z  tensor([0.1914, 0.9667, 0.2959, 0.9281], requires_grad=True)\n",
      "new x  tensor([0.9829, 0.8345, 0.3054, 0.6207])\n",
      "tensor([0.3428, 0.1822, 0.3914, 0.0169])\n",
      "tensor([2.1914, 2.9667, 2.2959, 2.9281])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,requires_grad=True)\n",
    "y = torch.rand(4,requires_grad=True)\n",
    "z = torch.rand(4,requires_grad=True)\n",
    "print('x ', x)\n",
    "print('y ', y)\n",
    "print('z ', z)\n",
    "\n",
    "# first method\n",
    "x.requires_grad=False\n",
    "print('new x ', x)\n",
    "\n",
    "#second method\n",
    "print(y.detach())\n",
    "\n",
    "#third method\n",
    "with torch.no_grad():\n",
    "    print(z+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3.])\n",
      "tensor([3., 3., 3.])\n",
      "tensor([3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "for epoch in range(3):\n",
    "    model = (x*3).sum()\n",
    "    model.backward()\n",
    "    print(x.grad)\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7360], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor(2)\n",
    "x = torch.rand(1)\n",
    "w = torch.tensor(1, dtype = torch.float, requires_grad=True)\n",
    "y_hat = w*x\n",
    "loss = (y-y_hat)**2\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression in numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 1.2 loss 30.000000\n",
      "epoch 3 w 1.871999988555908 loss 0.768000\n",
      "epoch 5 w 1.9795200133323667 loss 0.019661\n",
      "epoch 7 w 1.9967231869697568 loss 0.000503\n",
      "epoch 9 w 1.999475698471069 loss 0.000013\n",
      "epoch 11 w 1.9999160599708554 loss 0.000000\n",
      "epoch 13 w 1.9999865984916685 loss 0.000000\n",
      "epoch 15 w 1.9999978351593015 loss 0.000000\n",
      "epoch 17 w 1.9999996304512022 loss 0.000000\n",
      "epoch 19 w 1.9999999165534972 loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4], dtype=np.float32)\n",
    "y= np.array([2,4,6,8], dtype=np.float32)\n",
    "w= 0.0\n",
    "\n",
    "def forward(X):\n",
    "    return w * X\n",
    "\n",
    "def loss(Y, Y_pred):\n",
    "    return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "def gradient(X, Y, Y_pred):\n",
    "    return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "n_iter = 20\n",
    "lr = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    pred = forward(x)\n",
    "    l = loss(y,pred)\n",
    "    dw = gradient(x,y,pred)\n",
    "    w -= lr*dw\n",
    "    if epoch %2 ==0:\n",
    "        print(f'epoch {epoch+1} w {w} loss {l:3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 0.29999998211860657 loss 30.000000\n",
      "epoch 101 w 1.9999996423721313 loss 0.000000\n",
      "epoch 201 w 1.9999996423721313 loss 0.000000\n",
      "epoch 301 w 1.9999996423721313 loss 0.000000\n",
      "epoch 401 w 1.9999996423721313 loss 0.000000\n",
      "epoch 501 w 1.9999996423721313 loss 0.000000\n",
      "epoch 601 w 1.9999996423721313 loss 0.000000\n",
      "epoch 701 w 1.9999996423721313 loss 0.000000\n",
      "epoch 801 w 1.9999996423721313 loss 0.000000\n",
      "epoch 901 w 1.9999996423721313 loss 0.000000\n",
      "prediction after training 10.00\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "y= torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "def forward(X):\n",
    "    return w * X\n",
    "\n",
    "def loss(Y, Y_pred):\n",
    "    return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "# def gradient(X, Y, Y_pred):\n",
    "#     return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "n_iter = 1000\n",
    "lr = 0.01\n",
    "for epoch in range(n_iter):\n",
    "    pred = forward(x)\n",
    "    l = loss(y,pred)\n",
    "    l.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= lr*w.grad\n",
    "    w.grad.zero_()\n",
    "    if epoch %100 ==0:\n",
    "        print(f'epoch {epoch+1} w {w} loss {l:3f}')\n",
    "print(f\"prediction after training {forward(5):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace parts with torch functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 0.0009669065475463867 loss 55.290382\n",
      "epoch 1001 w 2.0015087127685547 loss 0.000003\n",
      "epoch 2001 w 2.0000765323638916 loss 0.000000\n",
      "last epoch 2040 w 2.0000674724578857 loss 0.000000\n",
      "prediction after training 10.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "n_iter = 10000\n",
    "lr = 0.01\n",
    "\n",
    "#x= torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "#y= torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "x= torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "y= torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "x_test= torch.tensor([[5]], dtype=torch.float32)\n",
    "n_samples, n_features  = x.shape\n",
    "n_inputs, n_outputs = n_features,n_features\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "model = nn.Linear(n_inputs, n_outputs)\n",
    "#def forward(X):\n",
    "#   return w * X\n",
    "\n",
    "## replace loss with MSEloss\n",
    "loss= nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) # will be used to do update\n",
    "#def loss(Y, Y_pred):\n",
    " #   return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "# def gradient(X, Y, Y_pred):\n",
    "#     return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "w_prev = 99999999\n",
    "for epoch in range(n_iter):\n",
    "    pred = model(x)\n",
    "    l = loss(y,pred)\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    " #   with torch.no_grad():\n",
    " #       w -= lr*w.grad\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #w.grad.zero_()\n",
    "    w,b = model.parameters()\n",
    "    w_now = w[0][0].item()\n",
    "    if w_now == w_prev:\n",
    "        print(f'last epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "        break\n",
    "    w_prev = w_now\n",
    "    if epoch %1000 ==0:\n",
    "        w,b = model.parameters()\n",
    "        print(f'epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "print(f\"prediction after training {model(x_test).item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 w 1.0181353092193604 loss 10.668782\n",
      "epoch 1001 w 1.9954642057418823 loss 0.000030\n",
      "epoch 2001 w 1.9997735023498535 loss 0.000000\n",
      "last epoch 2635 w 1.9999659061431885 loss 0.000000\n",
      "prediction after training 10.00\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "n_iter = 10000\n",
    "lr = 0.01\n",
    "\n",
    "#x= torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "#y= torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "x= torch.tensor([[1],[2],[3],[4]], dtype=torch.float32)\n",
    "y= torch.tensor([[2],[4],[6],[8]], dtype=torch.float32)\n",
    "x_test= torch.tensor([[5]], dtype=torch.float32)\n",
    "n_samples, n_features  = x.shape\n",
    "n_inputs, n_outputs = n_features,n_features\n",
    "#w= torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self,input_size, output_size):\n",
    "        super(LinearRegression,self).__init__()\n",
    "        self.lin = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.lin(x)\n",
    "\n",
    "model = LinearRegression(n_inputs, n_outputs)\n",
    "#def forward(X):\n",
    "#   return w * X\n",
    "\n",
    "## replace loss with MSEloss\n",
    "loss= nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr) # will be used to do update\n",
    "#def loss(Y, Y_pred):\n",
    " #   return ((Y_pred-Y)**2).mean()\n",
    "\n",
    "# def gradient(X, Y, Y_pred):\n",
    "#     return np.dot(2*X, Y_pred-Y).mean()\n",
    "\n",
    "\n",
    "\n",
    "w_prev = 99999999\n",
    "for epoch in range(n_iter):\n",
    "    pred = model(x)\n",
    "    l = loss(y,pred)\n",
    "    l.backward()\n",
    "\n",
    "    optimizer.step()\n",
    " #   with torch.no_grad():\n",
    " #       w -= lr*w.grad\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #w.grad.zero_()\n",
    "    w,b = model.parameters()\n",
    "    w_now = w[0][0].item()\n",
    "    if w_now == w_prev:\n",
    "        print(f'last epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "        break\n",
    "    w_prev = w_now\n",
    "    if epoch %1000 ==0:\n",
    "        w,b = model.parameters()\n",
    "        print(f'epoch {epoch+1} w {w[0][0].item()} loss {l:3f}')\n",
    "print(f\"prediction after training {model(x_test).item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## prepare the data\n",
    "X_data, y_data = datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f70c7a9606a5e5d45528e7f69679ef4ea09776be7c678f056a6d043a06b07958"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
